{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n",
    "\n",
    "## 概述\n",
    "决策树 $（Decision Tree）$ 属于有监督学习，有分类树也有决策树\n",
    "\n",
    "节点分类\n",
    "- 根节点：没有入度，只有出度\n",
    "- 中间节点：既有出度也有入度，入度均为 $1$，出度不限\n",
    "- 叶节点：没有出度，只有入度，入度均为 $1$。**每个叶节点都是一个类别标签**\n",
    "\n",
    "两个相邻节点中，更靠近根节点的称为 **父节点**，另一个称为 **子节点**\n",
    "\n",
    "可以把决策树看作一个 $if-then$ 规则的集合\n",
    "- 由决策树根节点到叶节点的每一条路径构建一条规则\n",
    "- 路径上中间节点的特征对应着规则的条件，叶节点的标签对应着规则的结论。\n",
    "\n",
    "决策树的路径或者其对应的 $if-then$ 规则集合有一个重要的性质：互斥并且完备。也就是说，每一个实例都被 **有且仅有一条** 路径或者规则所覆盖。这里的覆盖指的是实例的特征与路径上的特征一致，或实例满足规则的条件。\n",
    "\n",
    "## 构建决策树的准备工作\n",
    "### 1、特征选择\n",
    "特征选择就是决定用哪个特征来划分特征空间，其目的在于选取对训练数据具有分类能力的特征。这\n",
    "样可以提高决策树学习的效率。如果利用一个特征进行分类的结果与随机分类的结果没有很大的差别，\n",
    "则称这个特征是没有分类能力的，经验上扔掉这些特征对决策树学习的精度影响不会很大。\n",
    "\n",
    "一般而言，随着划分过程不断进行，我们希望决策树的分支节点\n",
    "所包含的样本尽可能属于同一类别，也就是节点的 **纯度** $（purity）$ 越来越高。\n",
    "\n",
    "实际使用中，衡量的度量一般是 **不纯度**，度量不纯度的指标有：熵、增益率、基尼指数\n",
    "\n",
    "#### 1.1、香农熵及其计算函数\n",
    "熵定义为信息的期望值，概率统计中，一般表示随机变量不确定性的度量\n",
    "\n",
    "假定当前样本集合 $D$ 中一共有 $n$ 类样本，第 $i$ 类样本为 $x_i$，则 $x_i$ 的信息定义为：\n",
    "$$\n",
    "l(x_i) = -\\log_2p(x_i)\n",
    "$$\n",
    "其中 $p(x_i)$ 表示选择该分类的概率\n",
    "\n",
    "通过上式，可以得到所有类别的信息。为了计算熵，需要计算所有类别的所有可能值包含的信息期望值（数学期望），通过以下公式得到\n",
    "$$\n",
    "Ent(D) = -\\sum_{i=1}^n p(x_i) l(x_i)\n",
    "$$\n",
    "$Ent(D)$ 的值越小，$D$ 的不纯度越低\n",
    "\n",
    "计算香农熵的 $python$ 代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calEnt(dataSet):\n",
    "    \"\"\"计算香农熵\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataSet : \n",
    "        原始数据集\n",
    "    \"\"\"\n",
    "    n = dataSet.shape[0] # 数据集行数\n",
    "    labelSet = dataSet.iloc[:, -1].value_counts() # 标签所有类别\n",
    "    p = labelSet / n # 每一类标签所占百分比\n",
    "    ent = (-p*np.log2(p)).sum() # 计算信息熵\n",
    "    return ent    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 构建数据集进行计算信息熵的测试\n",
    "def createDataSet():\n",
    "    row_data = {'no surfacing':[1,1,1,0,0],\n",
    "                'flippers':[1,1,0,1,1],\n",
    "                'fish':['yes','yes','no','no','no']}\n",
    "    dataSet = pd.DataFrame(row_data)\n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no surfacing  flippers fish\n",
       "0             1         1  yes\n",
       "1             1         1  yes\n",
       "2             1         0   no\n",
       "3             0         1   no\n",
       "4             0         1   no"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = createDataSet()\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calEnt(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵越高，信息的不纯度就越高，也就是混合的数据就越多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2、信息增益\n",
    "信息增益 $（Information Gain）$ 的计算公式就是父节点的信息熵与其下所有总信息熵之差。要注意的是，此时计算子节点的总信息熵不能简单求和，而要求在求和汇总之前进行修正\n",
    "\n",
    "假设离散属性 $a$ 有 $V$ 个可能的取值 ${a_1,a_2,\\cdots ,a_v}$，若使用 $a$ 对样本数据集 $D$ 进行划分，则产生 $V$ 个分支节点，其中第 $v$ 个分支节点包含了 $D$ 中所有在属性 $a$ 上取值为 $a_v$ 的样本，记为 $D_v$。可根据信息熵的公式计算出 $D_v$ 的信息熵，再考虑到不同分支节点所包含的样本数不同，给分支节点赋予权重 $|D_v|/|D|$，这就是所谓的修正。\n",
    "\n",
    "所以信息增益的计算公式为\n",
    "$$\n",
    "Gain(D,a) = Ent(D) - \\sum_{i=1}^V \\frac{|D_v|}{|D|} * Ent(D_v)\n",
    "$$\n",
    "\n",
    "则上面数据集中第 $0$ 列的信息增益为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4199730940219749"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=(3/5)*(-(2/3)*np.log2(2/3)-(1/3)*np.log2(1/3))\n",
    "calEnt(dataSet)-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、数据集最佳切分函数\n",
    "划分数据集的最佳准则是选择 **最大信息增益**，也就是信息下降最快的方向。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestSplit(dataSet):\n",
    "    \"\"\"选择最佳分割特征和分割点\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataSet : \n",
    "        原始数据集\n",
    "    return : \n",
    "        数据集最佳切分列的索引\n",
    "    \"\"\"\n",
    "    baseEnt = calEnt(dataSet) # 计算原始熵\n",
    "    bestGain = 0 # 初始化信息熵\n",
    "    axis = -1 # 初始化最佳切分列（标签列）\n",
    "    for i in range(dataSet.shape[-1] - 1): # 对特征的每一列进行遍历\n",
    "        levels = dataSet.iloc[:, i].value_counts().index # 提取出当前列的所有取值\n",
    "        ents = 0 # 初始化子节点的信息熵\n",
    "        for j in levels: # 对当前列的每一个取值进行循环\n",
    "            childSet = dataSet[dataSet.iloc[:, i] == j] # 某一个子节点的 dataFrame\n",
    "            ent = calEnt(childSet) # 计算某一个子节点的信息熵\n",
    "            ents += (childSet.shape[0]/dataSet.shape[0])*ent # 计算当前列的信息熵\n",
    "        infoGain = baseEnt-ents # 计算当前列的信息增益\n",
    "        # print(f'第{i}列的信息增益为{infoGain}')\n",
    "        if (infoGain > bestGain):\n",
    "            bestGain = infoGain # 更新最佳信息增益\n",
    "            axis = i # 最大信息增益所在列的索引\n",
    "    return axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestSplit(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、按照给定列切分数据集\n",
    "通过最佳切分函数返回最佳切分列索引，就可以根据这个索引，构建一个按照给定列切分数据集的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySplit(dataSet, axis, value):\n",
    "    \"\"\"按照给定的列划分数据集\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataSet : \n",
    "        原始数据集\n",
    "    axis : \n",
    "        指定的列索引\n",
    "    value : \n",
    "        指定的属性值\n",
    "    \"\"\"\n",
    "    col = dataSet.columns[axis]\n",
    "    redataSet = dataSet.loc[dataSet[col] == value,:].drop(col,axis=1)\n",
    "    return redataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证函数，以 `axis = 0`, `vaule = 1`为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flippers fish\n",
       "0         1  yes\n",
       "1         1  yes\n",
       "2         0   no"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySplit(dataSet, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 递归构建决策树\n",
    "### *ID3* 算法\n",
    "*ID3* 算法的核心是在决策树各个节点上对应信息增益准则选择特征，递归地构建决策树。具体方法是：从根节点开始，对节点计算所有可能的特征的信息增益，选择信息增益最大的特征作为节点的特征，由该特征的不同取值建立子节点；再对子节点递归地调用以上方法，构建决策树；知道所有特征的信息增益均很小或没有特征可以选择为止，最后得到一个决策树。\n",
    "\n",
    "递归结束的条件是：程序遍历完所有的特征列，或者每个分支下的所有实例都具有相同分类。如果所有实例具有相同分类，则得到一个叶节点。任何到达叶节点的数据必然属于叶节点的分类，即叶节点里面必须是标签。\n",
    "\n",
    "### 构建决策树的 *python* 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet):\n",
    "    \"\"\"基于最大信息增益切分数据集，递归构建决策树\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataSet : \n",
    "        原始数据集（最后一列是标签）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    myTree :\n",
    "        字典形式的树\n",
    "    \"\"\"    \n",
    "    featlist = list(dataSet.columns) #提取出数据集所有的列\n",
    "    classlist = dataSet.iloc[:,-1].value_counts() #获取最后一列类标签\n",
    "    #判断最多标签数目是否等于数据集行数，或者数据集是否只有一列\n",
    "    if classlist[0]==dataSet.shape[0] or dataSet.shape[1] == 1:\n",
    "        return classlist.index[0] #如果是，返回类标签\n",
    "    axis = bestSplit(dataSet) #确定出当前最佳切分列的索引\n",
    "    bestfeat = featlist[axis] #获取该索引对应的特征\n",
    "    myTree = {bestfeat:{}} #采用字典嵌套的方式存储树信息\n",
    "    del featlist[axis] #删除当前特征\n",
    "    valuelist = set(dataSet.iloc[:,axis]) #提取最佳切分列所有属性值\n",
    "    for value in valuelist: #对每一个属性值递归建树\n",
    "        myTree[bestfeat][value] = createTree(mySplit(dataSet,axis,value))\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTree = createTree(dataSet)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树存储\n",
    "使用 $numpy$ 中的 $save()$ 函数，将字典形式的数据直接保存成 $.npy$ 文件，需要调用时直接使用 $load()$ 函数即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('myTree.npy',myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_myTree = np.load('myTree.npy', allow_pickle=True).item()\n",
    "read_myTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用决策树执行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(inputTree,labels, testVec):\n",
    "    \"\"\"使用已构建的决策树对一个测试实例进行分类\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inputTree : \n",
    "        已构建的决策树\n",
    "    labels : \n",
    "        存储选择的最优特征标签\n",
    "    testVec : \n",
    "        测试数据列表，顺序对应原始数据集\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    classLabel :\n",
    "        分类结果\n",
    "    \"\"\"        \n",
    "    firstStr = next(iter(inputTree)) #获取决策树第一个节点\n",
    "    secondDict = inputTree[firstStr] #下一个字典\n",
    "    featIndex = labels.index(firstStr) #第一个节点所在列的索引\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]) == dict :\n",
    "                classLabel = classify(secondDict[key], labels, testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：\n",
    "- $python3$ 中 `myTree.keys()` 返回的是 `dict_keys` 类型而不是 `list` 类型，因此可以使用 `list(myTree.keys())[0]` 获取节点属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_classify(train,test):\n",
    "    \"\"\"对测试集进行预测，并返回预测的结果\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train : \n",
    "        训练集\n",
    "    test : \n",
    "        测试集\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test :\n",
    "        完成分类的测试集\n",
    "    \"\"\"    \n",
    "    inputTree = createTree(train) #根据测试集生成一棵树\n",
    "    labels = list(train.columns) #数据集所有的列名称\n",
    "    result = []\n",
    "    for i in range(test.shape[0]): #对测试集中每一条数据进行循环\n",
    "        testVec = test.iloc[i,:-1] #测试集中的一个实例\n",
    "        classLabel = classify(inputTree,labels,testVec) #预测该实例的分类\n",
    "        result.append(classLabel) #将分类结果追加到result列表中\n",
    "    test['predict']=result #将预测结果追加到测试集最后一列\n",
    "    acc = (test.iloc[:,-1]==test.iloc[:,-2]).mean() #计算准确率\n",
    "    print(f'模型预测准确率为{acc}')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测准确率为1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11065\\AppData\\Local\\Temp/ipykernel_27908/1597897043.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['predict']=result #将预测结果追加到测试集最后一列\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no surfacing</th>\n",
       "      <th>flippers</th>\n",
       "      <th>fish</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no surfacing  flippers fish predict\n",
       "0             1         1  yes     yes\n",
       "1             1         1  yes     yes\n",
       "2             1         0   no      no"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataSet\n",
    "test = dataSet.iloc[:3,:]\n",
    "acc_classify(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 $SKlearn$ 中 $graphviz$ 包实现决策树的绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'graphviz' has no attribute 'Source'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27908/2935495402.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                                 \u001b[0mfilled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                                 special_characters=True)\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m#利用render方法生成图形\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'graphviz' has no attribute 'Source'"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz\n",
    "#特征\n",
    "Xtrain = dataSet.iloc[:,:-1]\n",
    "#标签\n",
    "Ytrain = dataSet.iloc[:,-1]\n",
    "labels = Ytrain.unique().tolist()\n",
    "Ytrain = Ytrain.apply(lambda x: labels.index(x)) #将本文转换为数字\n",
    "#绘制树模型\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(Xtrain, Ytrain)\n",
    "tree.export_graphviz(clf)\n",
    "\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "# graphviz.Source(dot_data)\n",
    "\n",
    "#给图形增加标签和颜色\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=['no surfacing', 'flippers'],\n",
    "                                class_names=['fish', 'not fish'],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graphviz.Source(dot_data)\n",
    "#利用render方法生成图形\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"fish\")\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树可视化\n",
    "使用 `matplotlib` 中的注解工具 `annotation` 进行绘制\n",
    "可视化需要使用的函数：\n",
    "- `getNumLeafs`：获取决策树叶子节点的数目\n",
    "- `getTreeDepth`：获取决策树深度\n",
    "- `plotNode`：绘制节点\n",
    "- `plotMidText`：绘制节点间的文本\n",
    "- `plotTree`：绘制决策树\n",
    "- `createPlot`：创建绘制面板（主函数）\n",
    "\n",
    "### 1、计算叶子节点数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumLeafs(myTree):\n",
    "    \"\"\"递归计算叶子节点个数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    myTree : \n",
    "        字典形式的树\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numLeafs :\n",
    "        叶子节点个数\n",
    "    \"\"\"    \n",
    "    numLeafs = 0 #初始化叶节点数目\n",
    "    firstStr = next(iter(myTree)) #获得树的第一个键值，即第一个特征\n",
    "    secondDict = myTree[firstStr] #获取下一组字典\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]) == dict: #测试该节点是否为字典\n",
    "            numLeafs += getNumLeafs(secondDict[key]) #是字典，递归，循环计算新分支叶节点数\n",
    "        else:\n",
    "            numLeafs +=1 #不是字典，代表此结点为叶子结点\n",
    "    return numLeafs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、计算决策树的深度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTreeDepth(myTree):\n",
    "    \"\"\"递归计算树的深度\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    myTree : \n",
    "        字典形式的树\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    maxDepth :\n",
    "        树的最大深度\n",
    "    \"\"\"    \n",
    "    maxDepth = 0\n",
    "    firstStr = next(iter(myTree))\n",
    "    secondDict = myTree[firstStr]\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]) == dict:\n",
    "            thisDepth = 1+getTreeDepth(secondDict[key])\n",
    "        else:\n",
    "            thisDepth = 1\n",
    "        if thisDepth>maxDepth:\n",
    "            maxDepth = thisDepth\n",
    "    return maxDepth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、绘制节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNode(nodeTxt, cntrPt, parentPt, nodeType):\n",
    "    \"\"\"绘制节点\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nodeTxt : \n",
    "        节点名\n",
    "    cntrPt : \n",
    "        文本位置\n",
    "    parentPt : \n",
    "        标注的箭头位置\n",
    "    nodeType : \n",
    "        节点格式\n",
    "    \"\"\"    \n",
    "    arrow_args = dict(arrowstyle=\"<-\") #定义箭头格式\n",
    "    createPlot.ax1.annotate(nodeTxt,\n",
    "                            xy=parentPt,xycoords='axes fraction',\n",
    "                            xytext=cntrPt, textcoords='axes fraction',\n",
    "                            va=\"center\", ha=\"center\",\n",
    "                            bbox=nodeType,\n",
    "                            arrowprops=arrow_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、标注有向边属性值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMidText(cntrPt, parentPt, txtString):\n",
    "    \"\"\"标注有向边属性值\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cntrPt : \n",
    "        用于计算标注位置\n",
    "    parentPt : \n",
    "        用于计算标注位置\n",
    "    txtString : \n",
    "        标注的内容\n",
    "    \"\"\"    \n",
    "    xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0] #计算标注位置的横坐标\n",
    "    yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1] #计算标注位置的纵坐标\n",
    "    createPlot.ax1.text(xMid, yMid, txtString, va=\"center\", ha=\"center\",\n",
    "                        rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、绘制决策树\n",
    "整体算法递归思路分三个步骤：\n",
    "- 绘制自身\n",
    "- 判断子节点非叶节点，递归\n",
    "- 判断子节点为叶节点，绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTree(myTree, parentPt, nodeTxt):\n",
    "    \"\"\"绘制决策树\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    myTree : \n",
    "        字典形式的决策树\n",
    "    parentPt : \n",
    "        标注的内容\n",
    "    nodeTxt : \n",
    "        节点名\n",
    "    \"\"\"    \n",
    "    decisionNode = dict(boxstyle=\"sawtooth\", fc=\"0.8\") #设置中间节点格式\n",
    "    leafNode = dict(boxstyle=\"round4\", fc=\"0.8\") #设置叶节点格式\n",
    "    numLeafs = getNumLeafs(myTree) #获取决策树叶结点数目，决定了树的宽度\n",
    "    depth = getTreeDepth(myTree) #获取决策树层数\n",
    "    firstStr = next(iter(myTree)) #下个字典\n",
    "    cntrPt = (plotTree.xOff+\n",
    "                    (1.0+float(numLeafs))/2.0/plotTree.totalW,plotTree.yOff)#确定中心位置\n",
    "    plotMidText(cntrPt, parentPt, nodeTxt) #标注有向边属性值\n",
    "    plotNode(firstStr, cntrPt, parentPt, decisionNode) #绘制节点\n",
    "    secondDict = myTree[firstStr] #下一个字典，也就是继续绘制子结点\n",
    "    plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD #y偏移\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key])== dict: #测试该结点是否为字典\n",
    "            plotTree(secondDict[key],cntrPt,str(key)) #是字典则不是叶结点，递归调用继续绘制\n",
    "        else:\n",
    "            plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW #x偏移\n",
    "            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)\n",
    "            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key))\n",
    "    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、创建绘制面板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPlot(inTree):\n",
    "    \"\"\"创建绘制面板\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inTree : \n",
    "        字典形式的决策树\n",
    "    \"\"\"    \n",
    "    fig = plt.figure(1, facecolor='white') #创建fig\n",
    "    fig.clf() #清空fig\n",
    "    axprops = dict(xticks=[], yticks=[])\n",
    "    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops) #去掉x、y轴\n",
    "    plotTree.totalW = float(getNumLeafs(inTree)) #获取决策树叶结点数目\n",
    "    plotTree.totalD = float(getTreeDepth(inTree)) #获取决策树深度\n",
    "    plotTree.xOff = -0.5/plotTree.totalW #x偏移\n",
    "    plotTree.yOff = 1.0 #y偏移\n",
    "    plotTree(inTree, (0.5,1.0), '') #绘制决策树\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "createPlot(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法总结\n",
    "决策树优点;\n",
    "- 能够可视化，容易理解和解释\n",
    "- 数据准备工作少。（其他算法通常需要数据规范化，需要创建虚拟变量并删除空值等）\n",
    "- 能够哦同时处理数值和分类数据，既可以做回归也可以做分类\n",
    "- 效率高，决策树只需要进行一次构建，反复使用，每一次预测的最大计算次数不超过决策树的最大深度\n",
    "- 能够处理多输出问题，即含有多个标签的问题\n",
    "- 是一个白盒模型，结果能够很容易被解释。如果在模型中能够观察到给定情况，则可以通过布尔逻辑轻松解释条件。相反，在黑盒模型中（例如人工神经网络），结果可能难以解释\n",
    "\n",
    "决策树缺点：\n",
    "- 递归生成树的方法容易造成过拟合\n",
    "- 决策树可能是不稳定的，因为即使非常小的差异，也可能产生一棵完全不同的树\n",
    "- 如果某些分类占优势，决策树将会创建一棵有偏差的树。因此，建议在拟合决策树之前平衡数据集"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8baf67d759dc41d084056de23fe305760a7ffcb21bd78a2ec1cf32b9bc94016f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
